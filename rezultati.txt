
#################################################################
SARSA: N = 100 000

CURRENT V
[[0.71687648 0.80034384 0.89452021 1.         0.        ]
 [0.64121569        nan 0.80145625 0.89482999 0.        ]
 [0.57317889 0.64391384 0.71853614 0.77123877 0.68412166]]
CURRENT POLICY
[[b'R' b'R' b'R' b'R' '']
 [b'U' '' b'U' b'U' '']
 [b'U' b'R' b'U' b'U' b'L']]
####################################################################

#Value iteration

CURRENT V
[[0.729   0.81    0.9     1.      0.     ]
 [0.6561      nan 0.81    0.9     0.     ]
 [0.59049 0.6561  0.729   0.81    0.729  ]]
CURRENT POLICY
[[b'R' b'R' b'R' b'R' '']
 [b'U' '' b'R' b'U' '']
 [b'R' b'R' b'R' b'U' b'L']]

##########################################################################

MC

CURRENT V
[[0.67570107 0.76085271 0.86005466 0.97128137 0.        ]
 [0.59499357        nan 0.76652146 0.69673586 0.        ]
 [0.55545496 0.58987679 0.6779729  0.68478392 0.03199001]]
CURRENT POLICY
[[b'R' b'R' b'R' b'R' '']
 [b'U' '' b'U' b'U' '']
 [b'R' b'R' b'U' b'U' b'L']]

##########################################################################

Q-learning 
N = 100 000
CURRENT V
[[0.729   0.81    0.9     1.      0.     ]
 [0.6561      nan 0.81    0.9     0.     ]
 [0.59049 0.6561  0.729   0.81    0.729  ]]
CURRENT POLICY
[[b'R' b'R' b'R' b'R' '']
 [b'U' '' b'R' b'U' '']
 [b'R' b'R' b'R' b'U' b'L']]

##################################################################################
Q-learning 
N = 10 000

CURRENT V
[[0.729   0.81    0.9     1.      0.     ]
 [0.6561      nan 0.81    0.9     0.     ]
 [0.59049 0.6561  0.729   0.81    0.729  ]]
CURRENT POLICY
[[b'R' b'R' b'R' b'R' '']
 [b'U' '' b'R' b'U' '']
 [b'R' b'R' b'R' b'U' b'L']]

################################################################################